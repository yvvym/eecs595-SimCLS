{"article": ["it seems like it would be possible for the computer to take the most logical approach, but programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making those decisions.", "in essence the computer would act as a completely sociopathic entity, not taking human emotion and context in question.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime for each and every possible situation because we as humans are unable to currently program much less comprehend as universal function for \"gray morality\".", "sorry for the wall of text."], "abstract": ["computers would work great if we wanted unbiased yet sociopathic judges, but they are unable to comprehend every gray zone of morality because we are unable to program every situation."], "candidates": [[["it seems like it would be possible for the computer to take the most logical approach, but programming to use ai morality would be very hard.", "the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a"], 0.1986986986986987], [["programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of"], 0.17167167167167166], [["programming ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime"], 0.1693759512937595], [["programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them"], 0.17403048427551612], [["a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime for each and every possible situation.", "a computer would act as a completely sociopathic entity, not taking human emotion and"], 0.17142142142142144], [["programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as human would have a very difficult if"], 0.20795795795795793], [["the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making those decisions.", "in essence the computer would act as a completely sociopathic entity, not taking human emotion"], 0.17403048427551612], [["programming a computer with a universal standard of morality is very difficult.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime.", "in essence the computer would act as a completely"], 0.15159817351598173], [["programming a computer with ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve"], 0.17403048427551612], [["the idea of ai morality is very hard to program.", "even humans don't have a perfected standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime."], 0.18093093093093093], [["a computer could be programmed to have a universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making."], 0.21657754010695185], [["computer would have to make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making.", "in essence the computer would act as a completely sociopathic entity.", "a computer would not be"], 0.19229532445816447], [["programming a computer with a universal standard of morality is very difficult.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime."], 0.17234848484848483], [["computer would have to make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making.", "in essence the computer would act as a completely sociopathic entity."], 0.20647653000594177], [["even we as humans don't have a perfected universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as human would have a very difficult time making."], 0.20610500610500607], [["computer could be programmed to have a universal standard of morality.", "computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult time making."], 0.22688172043010754]], "article_untok": ["it seems like it would be possible for the computer to take the most logical approach, but programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making those decisions.", "in essence the computer would act as a completely sociopathic entity, not taking human emotion and context in question.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime for each and every possible situation because we as humans are unable to currently program much less comprehend as universal function for \"gray morality\".", "sorry for the wall of text."], "abstract_untok": ["computers would work great if we wanted unbiased yet sociopathic judges, but they are unable to comprehend every gray zone of morality because we are unable to program every situation."], "candidates_untok": [[["it seems like it would be possible for the computer to take the most logical approach, but programming to use ai morality would be very hard.", "the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a"], 0.1986986986986987], [["programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of"], 0.17167167167167166], [["programming ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime"], 0.1693759512937595], [["programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them"], 0.17403048427551612], [["a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime for each and every possible situation.", "a computer would act as a completely sociopathic entity, not taking human emotion and"], 0.17142142142142144], [["programming to use ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as human would have a very difficult if"], 0.20795795795795793], [["the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making those decisions.", "in essence the computer would act as a completely sociopathic entity, not taking human emotion"], 0.17403048427551612], [["programming a computer with a universal standard of morality is very difficult.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime.", "in essence the computer would act as a completely"], 0.15159817351598173], [["programming a computer with ai morality would be very hard since even we as humans don't have a perfected universal standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve"], 0.17403048427551612], [["the idea of ai morality is very hard to program.", "even humans don't have a perfected standard of morality.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime."], 0.18093093093093093], [["a computer could be programmed to have a universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making."], 0.21657754010695185], [["computer would have to make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making.", "in essence the computer would act as a completely sociopathic entity.", "a computer would not be"], 0.19229532445816447], [["programming a computer with a universal standard of morality is very difficult.", "a computer would not be able to completely judge if a person's innocent intentions is enough to absolve them of a wrongful crime."], 0.17234848484848483], [["computer would have to make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult if at all possible time making.", "in essence the computer would act as a completely sociopathic entity."], 0.20647653000594177], [["even we as humans don't have a perfected universal standard of morality.", "the computer would make decisions in situations of \"gray zone morality\" that we as human would have a very difficult time making."], 0.20610500610500607], [["computer could be programmed to have a universal standard of morality.", "computer would make decisions in situations of \"gray zone morality\" that we as humans would have a very difficult time making."], 0.22688172043010754]]}