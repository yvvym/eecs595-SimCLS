{"article": ["i am an ai software engineer, but people seem to not understand the subject.", "even people who work with it or people who try to understand it.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be a threat unless you hard-program it to be so.", "or, you program ai so that it is stupid (like skynet), and therefore has human ideas like \"survival\" and \"fears threats irrationally\" (therefore, fearing humans; 'omg what if they shut me down!').", "this thinking of seeing ai as a threat to humans, is a human tendency.", "it's human because it is almost as if the people pondering it, are assuming that ai will behave just like humans.", "such people are discounting and ignoring the bias of evolution has on the way we think.", "this is why sci-fi movies always scare you with ai.", "because they imagine that a super-intelligent ai will be \"human\" (because apparently, all ai programmers are trying to replicate the imperfection of humans [not true!]).", "if a super-intelligent ai, is \"human\", then they will have \"fears\" and \"survival instincts\" these are bred into us from evolution of millions of years.", "they do not apply to ai unless you specifically program ai to be this stupid.", "(in which case: blame those specific ai developers).", "the only real dangers from ai, is that they are super smart but secretly work for one of the ai developers.", "hard-coded to always help the original ai developer.", "or the ai developer installs biases or racist or nationalist feelings into the ai ?", "but i'm sure as you can detect any racist human, you can easily detect a blatantly racist ai and decide to re-program it and fire the ai developer who checked that code in.", "the ai will have no \"fears\" of being shut down.", "the ai will not be trying to attain \"human-like goals\" such as \"getting rich\" or \"controlling the world.\"", "it will serve purposes that aid humanity or a specific country.", "which is not that superior to say, a large group of scientists working together for similar objectives.", "finance nightmare   the worst nightmares are an ai that is connected to finances and has money at its disposal, and is programmed to make so much more money, that it destabilizes many economies.", "but this isn't a significant problem because there are plenty of non-ai software that can do it too.", "the ai wouldn't have much of a significant advantage over the many high-fidelity software in wall street already.", "it wouldn't work unless it was just given billions of dollars to play with and even then it would be no different than many of the hedge-fund billionaires we know today.", "super intelligence   if an ai is designed to be super logical (as it would be because that would be a significant advantage to build such an ai), then it would simply be like a super smart scientist or group of scientists, that give great advise.", "it wouldn't have ambitions of its own.", "it wouldn't think that humans need to be \"terminated\" because humans do have value and can be used to its advantage.", "if it starts a bunch of wars, lets say, once again, it wouldn't have such ambitions but if it did, then it would be no different than a cabal of generals and leaders making similar decisions.", "no one will buy a stupid ai.", "so you can count on the fact that if an ai is built and is super-intelligent, it will be super logical.", "if it is super logical, then it would make better decisions than our top scientists and top leaders of the world and it wouldn't try to \"drive us to extinction\" or \"enslave us\" or anything.", "conquering the world   even if the ai somehow came to a conclusion that everyone should listen to the ai, and conspired a plan to take over the world.", "it would still have to fight a huge war.", "it would be at best acting as a very strong powerful developed nations leader.", "it wouldn't be any superior to it.", "it wouldn't be taking risks like nuclear standoffs.", "nano scenarios.", "one nightmare is like nanotechnology (a bit like the tv show revolutions), but this is such a far-fetched idea that it would probably be a 1000 years before it becomes possible.", "a situation where the ai has god-like powers because it can affect all energy, matter and molecules anywhere it wants and all connected wirelessly to its colossal brain.", "it would basically be a god.", "if it even had that power, it would be smart enough to use those powers for good to benefit itself and probably a majority of humans because mutual-benefit in biology is superior to parasitic behavior.", "it wouldn't be trying to create an elite of humans and wipe out the rest.", "it simply isn't advantageous when it can simply restore order and create a somewhat fair system to serve its \"goals\" (which it usually won't have).", "genetic scenario   that one day the ai figures out how to manipulate genetics or create its own creatures or modify humans and their food completely.", "again this is just the same as nano scenarios.", "it would be powerful, but if it controls humans completely, then it wouldn't need to enslave them or harm them.", "sort of like how you don't harm your dog despite having all control over it."], "abstract": ["i've considered 100s of nightmare ai scenarios, and most of them are unrealistic or not as bad even if it did happen.", "i didn't write them all here, but no matter what you provide, the idea that a super-intelligent super-logical ai would have human goals and negative intentions is crazy and an irrational anti-technology fear.", "it would embrace mutual benefit, because it would understand evolution and biology, and co-exist with humanity for positive intentions.", "note that even the most evil men in humanity, stalin, hitler, pol pot, mao, these guys all had irrational belief systems that wouldn't exist in an ai.", "even if it did have terrible intentions, it would not be that much superior than a few national leaders with powerful armies.", "and no ones going to give armies to a machine.", "if the ai is super smart, national-leaders / generals will use the ai as an advisor, not a \"general\".", "edit: thanks for gold.", "added genetic scenario.", "feel free to pm me a nightmare scenario you think is worse or unpredictable etc.", "i'll be sure to tell my ai not to do it :).", "don't worry i won't be one of the scientists in the movies that tries to make \"a human\" ai that has no hard-coding.", "ai developers are not looking for imperfection (humans), we're looking for perfection so that we can make money."], "candidates": [[["i am an ai software engineer, but people seem to not understand the subject.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be"], 0.10957519698526892], [["ai software engineer: people seem to not understand the subject.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be a threat unless you"], 0.10241521068859198], [["people are assuming that ai will behave just like humans.", "this thinking of seeing ai as a threat to humans, is a human tendency.", "the only real dangers from ai, is that they are super smart but secretly work for one of the ai developers"], 0.14618831449182415], [["ai is not a threat unless you hard-program it to be so.", "it cannot be a threat if it is stupid (like skynet) or has human ideas like \"survival\" and \"fears threats irrationally\" the"], 0.1172701836908479], [["ai is not a threat unless you hard-program it to be so.", "it cannot be a threat if you program ai so that it is stupid (like skynet) or has human ideas like \"survival\" and \"f"], 0.12126540126540127], [["ai is not a threat unless you hard-program it to be so.", "it cannot be a threat if you program ai so that it is stupid (like skynet) or has human ideas like \"survival\" and \"fears"], 0.1261138861138861], [["people see ai as a threat to human species.", "it's not a threat unless you hard-program it to be so.", "this thinking of seeing ai as an threat is a human tendency.", "if an ai is designed to be super logical, it"], 0.1632387706855792], [["ai is not a threat unless you hard-program it to be so.", "this thinking of seeing ai as a threat to humans is a human tendency.", "the only real dangers from ai, is that they are super smart but secretly work for one of"], 0.15557763162858543], [["artificial intelligence (ai) is not a threat unless you hard-program it to be so.", "ai would not be trying to attain \"human-like goals\" such as \"getting rich\" or \"controlling the world\""], 0.12311097088666056], [["aims to explain why people see ai as a threat to humans.", "says it's not a threat unless you hard-program it to be so.", "if a super-intelligent ai, is \"human\", then they will have \"fears"], 0.1329383969815579], [["ai software engineer says people are wrong to think ai is a threat.", "he says people think ai will behave just like humans.", "he argues that if an ai is designed to be super logical, it would make better decisions than our top scientists and top"], 0.1221323211134419], [["ai is not a threat unless you hard-program it to be so, writes ai engineer.", "if an ai is designed to be super logical, then it would make better decisions than our top scientists and top leaders of the world."], 0.14586217753796651], [["i am an ai software engineer, but people seem to not understand the subject.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be"], 0.10957519698526892], [["ai engineer: people see ai as a threat to human species.", "it's not a threat unless you hard-program it to be so.", "this thinking of seeing ai as an threat is a human tendency."], 0.12172606268784886], [["ai engineer: people see ai as a threat to human species.", "it's not a threat unless you hard-program it to be so."], 0.08146408299080055], [["aims to explain why people see ai as a threat to humans.", "says it's not a threat unless you hard-program it to be so."], 0.08084663428174878]], "article_untok": ["i am an ai software engineer, but people seem to not understand the subject.", "even people who work with it or people who try to understand it.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be a threat unless you hard-program it to be so.", "or, you program ai so that it is stupid (like skynet), and therefore has human ideas like \"survival\" and \"fears threats irrationally\" (therefore, fearing humans; 'omg what if they shut me down!').", "this thinking of seeing ai as a threat to humans, is a human tendency.", "it's human because it is almost as if the people pondering it, are assuming that ai will behave just like humans.", "such people are discounting and ignoring the bias of evolution has on the way we think.", "this is why sci-fi movies always scare you with ai.", "because they imagine that a super-intelligent ai will be \"human\" (because apparently, all ai programmers are trying to replicate the imperfection of humans [not true!]).", "if a super-intelligent ai, is \"human\", then they will have \"fears\" and \"survival instincts\" these are bred into us from evolution of millions of years.", "they do not apply to ai unless you specifically program ai to be this stupid.", "(in which case: blame those specific ai developers).", "the only real dangers from ai, is that they are super smart but secretly work for one of the ai developers.", "hard-coded to always help the original ai developer.", "or the ai developer installs biases or racist or nationalist feelings into the ai ?", "but i'm sure as you can detect any racist human, you can easily detect a blatantly racist ai and decide to re-program it and fire the ai developer who checked that code in.", "the ai will have no \"fears\" of being shut down.", "the ai will not be trying to attain \"human-like goals\" such as \"getting rich\" or \"controlling the world.\"", "it will serve purposes that aid humanity or a specific country.", "which is not that superior to say, a large group of scientists working together for similar objectives.", "finance nightmare   the worst nightmares are an ai that is connected to finances and has money at its disposal, and is programmed to make so much more money, that it destabilizes many economies.", "but this isn't a significant problem because there are plenty of non-ai software that can do it too.", "the ai wouldn't have much of a significant advantage over the many high-fidelity software in wall street already.", "it wouldn't work unless it was just given billions of dollars to play with and even then it would be no different than many of the hedge-fund billionaires we know today.", "super intelligence   if an ai is designed to be super logical (as it would be because that would be a significant advantage to build such an ai), then it would simply be like a super smart scientist or group of scientists, that give great advise.", "it wouldn't have ambitions of its own.", "it wouldn't think that humans need to be \"terminated\" because humans do have value and can be used to its advantage.", "if it starts a bunch of wars, lets say, once again, it wouldn't have such ambitions but if it did, then it would be no different than a cabal of generals and leaders making similar decisions.", "no one will buy a stupid ai.", "so you can count on the fact that if an ai is built and is super-intelligent, it will be super logical.", "if it is super logical, then it would make better decisions than our top scientists and top leaders of the world and it wouldn't try to \"drive us to extinction\" or \"enslave us\" or anything.", "conquering the world   even if the ai somehow came to a conclusion that everyone should listen to the ai, and conspired a plan to take over the world.", "it would still have to fight a huge war.", "it would be at best acting as a very strong powerful developed nations leader.", "it wouldn't be any superior to it.", "it wouldn't be taking risks like nuclear standoffs.", "nano scenarios.", "one nightmare is like nanotechnology (a bit like the tv show revolutions), but this is such a far-fetched idea that it would probably be a 1000 years before it becomes possible.", "a situation where the ai has god-like powers because it can affect all energy, matter and molecules anywhere it wants and all connected wirelessly to its colossal brain.", "it would basically be a god.", "if it even had that power, it would be smart enough to use those powers for good to benefit itself and probably a majority of humans because mutual-benefit in biology is superior to parasitic behavior.", "it wouldn't be trying to create an elite of humans and wipe out the rest.", "it simply isn't advantageous when it can simply restore order and create a somewhat fair system to serve its \"goals\" (which it usually won't have).", "genetic scenario   that one day the ai figures out how to manipulate genetics or create its own creatures or modify humans and their food completely.", "again this is just the same as nano scenarios.", "it would be powerful, but if it controls humans completely, then it wouldn't need to enslave them or harm them.", "sort of like how you don't harm your dog despite having all control over it."], "abstract_untok": ["i've considered 100s of nightmare ai scenarios, and most of them are unrealistic or not as bad even if it did happen.", "i didn't write them all here, but no matter what you provide, the idea that a super-intelligent super-logical ai would have human goals and negative intentions is crazy and an irrational anti-technology fear.", "it would embrace mutual benefit, because it would understand evolution and biology, and co-exist with humanity for positive intentions.", "note that even the most evil men in humanity, stalin, hitler, pol pot, mao, these guys all had irrational belief systems that wouldn't exist in an ai.", "even if it did have terrible intentions, it would not be that much superior than a few national leaders with powerful armies.", "and no ones going to give armies to a machine.", "if the ai is super smart, national-leaders / generals will use the ai as an advisor, not a \"general\".", "edit: thanks for gold.", "added genetic scenario.", "feel free to pm me a nightmare scenario you think is worse or unpredictable etc.", "i'll be sure to tell my ai not to do it :).", "don't worry i won't be one of the scientists in the movies that tries to make \"a human\" ai that has no hard-coding.", "ai developers are not looking for imperfection (humans), we're looking for perfection so that we can make money."], "candidates_untok": [[["i am an ai software engineer, but people seem to not understand the subject.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be"], 0.10957519698526892], [["ai software engineer: people seem to not understand the subject.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be a threat unless you"], 0.10241521068859198], [["people are assuming that ai will behave just like humans.", "this thinking of seeing ai as a threat to humans, is a human tendency.", "the only real dangers from ai, is that they are super smart but secretly work for one of the ai developers"], 0.14618831449182415], [["ai is not a threat unless you hard-program it to be so.", "it cannot be a threat if it is stupid (like skynet) or has human ideas like \"survival\" and \"fears threats irrationally\" the"], 0.1172701836908479], [["ai is not a threat unless you hard-program it to be so.", "it cannot be a threat if you program ai so that it is stupid (like skynet) or has human ideas like \"survival\" and \"f"], 0.12126540126540127], [["ai is not a threat unless you hard-program it to be so.", "it cannot be a threat if you program ai so that it is stupid (like skynet) or has human ideas like \"survival\" and \"fears"], 0.1261138861138861], [["people see ai as a threat to human species.", "it's not a threat unless you hard-program it to be so.", "this thinking of seeing ai as an threat is a human tendency.", "if an ai is designed to be super logical, it"], 0.1632387706855792], [["ai is not a threat unless you hard-program it to be so.", "this thinking of seeing ai as a threat to humans is a human tendency.", "the only real dangers from ai, is that they are super smart but secretly work for one of"], 0.15557763162858543], [["artificial intelligence (ai) is not a threat unless you hard-program it to be so.", "ai would not be trying to attain \"human-like goals\" such as \"getting rich\" or \"controlling the world\""], 0.12311097088666056], [["aims to explain why people see ai as a threat to humans.", "says it's not a threat unless you hard-program it to be so.", "if a super-intelligent ai, is \"human\", then they will have \"fears"], 0.1329383969815579], [["ai software engineer says people are wrong to think ai is a threat.", "he says people think ai will behave just like humans.", "he argues that if an ai is designed to be super logical, it would make better decisions than our top scientists and top"], 0.1221323211134419], [["ai is not a threat unless you hard-program it to be so, writes ai engineer.", "if an ai is designed to be super logical, then it would make better decisions than our top scientists and top leaders of the world."], 0.14586217753796651], [["i am an ai software engineer, but people seem to not understand the subject.", "even great scientists can be fooled when speculating about this.", "basically, they see ai as a threat to human species.", "it's not a threat.", "it cannot be"], 0.10957519698526892], [["ai engineer: people see ai as a threat to human species.", "it's not a threat unless you hard-program it to be so.", "this thinking of seeing ai as an threat is a human tendency."], 0.12172606268784886], [["ai engineer: people see ai as a threat to human species.", "it's not a threat unless you hard-program it to be so."], 0.08146408299080055], [["aims to explain why people see ai as a threat to humans.", "says it's not a threat unless you hard-program it to be so."], 0.08084663428174878]]}